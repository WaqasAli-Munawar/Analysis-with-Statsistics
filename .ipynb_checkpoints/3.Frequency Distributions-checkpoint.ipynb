{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting data is just the starting point in a data analysis workflow. We rarely collect data just for the sake of collecting it. We collect data to analyze it, and we analyze it for different purposes:\n",
    "\n",
    "* To describe phenomena in the world (science).\n",
    "* To make better decisions (industries).\n",
    "* To improve systems (engineering).\n",
    "* To describe different aspects of our society (data journalism); etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our capacity to understand a data set just by looking at it in a table format is limited, and it decreases dramatically as the size of the data set increases. To be able to analyze data, we need to find ways to simplify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our capacity to understand a data set just by looking at it in a table format is limited, and it decreases dramatically as the size of the data set increases. To be able to analyze data, we need to find ways to simplify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnba = pd.read_csv(\"wnba.csv\")\n",
    "wnba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G      60\n",
       "F      33\n",
       "C      25\n",
       "G/F    13\n",
       "F/C    12\n",
       "Name: Pos, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency Distribution of Pos column\n",
    "freq_distro_pos = wnba['Pos'].value_counts()\n",
    "freq_distro_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency distribution table for the Pos variable, is measured on a nominal scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency distribution table for the Age variable\n",
    "age_ascending = wnba[\"Age\"].value_counts().sort_index()\n",
    "age_descending = wnba[\"Age\"].value_counts().sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age variable, is measured on a ratio scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have a variable measured on an ordinal scale in our data set, but let's use the PTS variable to create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pts_ordinal(pts):\n",
    "    if pts <= 20:\n",
    "        return \"very few points\"\n",
    "    elif 20 < pts <= 80:\n",
    "        return \"few points\"\n",
    "    elif (80 < pts <=  150):\n",
    "        return 'many, but below average'\n",
    "    elif (150 < pts <= 300):\n",
    "        return 'average number of points'\n",
    "    elif (300 < pts <=  450):\n",
    "        return 'more than average'\n",
    "    else:\n",
    "        return 'much more than average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTS</th>\n",
       "      <th>PTS_ordinal_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>many, but below average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>average number of points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>average number of points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188</td>\n",
       "      <td>average number of points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>few points</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PTS         PTS_ordinal_scale\n",
       "0   93   many, but below average\n",
       "1  217  average number of points\n",
       "2  218  average number of points\n",
       "3  188  average number of points\n",
       "4   50                few points"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnba['PTS_ordinal_scale'] = wnba[\"PTS\"].apply(make_pts_ordinal)\n",
    "wnba[[\"PTS\",'PTS_ordinal_scale']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method\n",
    "# def make_pts_ordinal(row):\n",
    "#     if row['PTS'] <= 20:\n",
    "#         return 'very few points'\n",
    "#     if (20 < row['PTS'] <=  80):\n",
    "#         return 'few points'\n",
    "#     if (80 < row['PTS'] <=  150):\n",
    "#         return 'many, but below average'\n",
    "#     if (150 < row['PTS'] <= 300):\n",
    "#         return 'average number of points'\n",
    "#     if (300 < row['PTS'] <=  450):\n",
    "#         return 'more than average'\n",
    "#     else:\n",
    "#         return 'much more than average'\n",
    "    \n",
    "# wnba['PTS_ordinal_scale'] = wnba.apply(make_pts_ordinal, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average number of points    45\n",
       "few points                  27\n",
       "many, but below average     25\n",
       "more than average           21\n",
       "much more than average      13\n",
       "very few points             12\n",
       "Name: PTS_ordinal_scale, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnba['PTS_ordinal_scale'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "much more than average      13\n",
       "more than average           21\n",
       "average number of points    45\n",
       "many, but below average     25\n",
       "few points                  27\n",
       "very few points             12\n",
       "Name: PTS_ordinal_scale, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order the table by unique values in a descending order (not alphabetically).\n",
    "# pts_ordinal_desc = wnba['PTS_ordinal_scale'].value_counts()[[\"much more than average\" ,\"more than average\" ,\n",
    "#                                                                 \" average number of points\",\"many, but below average\",\n",
    "#                                                                  \"few points\" ,\"very few points \"]]\n",
    "# pts_ordinal_desc = wnba['PTS_ordinal_scale'].value_counts().loc[[\"much more than average\" ,\"more than average\" ,\n",
    "#                                                                 \" average number of points\",\"many, but below average\",\n",
    "#                                                                  \"few points\" ,\"very few points \"]]\n",
    "pts_ordinal_desc = wnba['PTS_ordinal_scale'].value_counts().iloc[[4,3,0,2,1,5]]\n",
    "pts_ordinal_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because **proportions and percentages** are relative to the total number of instances in some set of data, they are called **relative frequencies**. In contrast, the frequencies we've been working with so far are called **absolute frequencies** because they are absolute counts and don't relate to the total number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21     1.398601\n",
       "22     6.993007\n",
       "23    10.489510\n",
       "24    11.188811\n",
       "25    10.489510\n",
       "26     8.391608\n",
       "27     9.090909\n",
       "28     9.790210\n",
       "29     5.594406\n",
       "30     6.293706\n",
       "31     5.594406\n",
       "32     5.594406\n",
       "33     2.097902\n",
       "34     3.496503\n",
       "35     2.797203\n",
       "36     0.699301\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion = wnba[\"Age\"].value_counts(normalize = True).sort_index()\n",
    "percentages = proportion*100\n",
    "percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.573426573426573"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of players are 30 years or older\n",
    "percentage_over_30 = percentages.loc[30:].sum()\n",
    "percentage_over_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.88111888111888\n"
     ]
    }
   ],
   "source": [
    "percentage_below_23 = percentages.loc[:23].sum() # slicing using loc, includes end limit. however iloc slicing doesnt include end limit\n",
    "print(percentage_below_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of players aged 23 years or younger is 19% (rounded to the nearest integer). This percentage is also called a percentile rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A percentile rank of a value X in a frequency distribution is given by the percentage of values that are equal or less than X ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, the value of 23 is called the 19th percentile. If a X value  is the 19th percentile, it means that 19% of all the values in the distribution are equal to or less than X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can arrive at the same answer a bit faster using the percentileofscore(a, score, kind='weak') function from scipy.stats. We need to use kind = 'weak' to indicate that we want to find the percentage of values thar are equal to or less than the value we specify in the score parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.88111888111888"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "\n",
    "percentileofscore(a = wnba[\"Age\"], score = 23, kind = \"weak\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another question we had was what percentage of players are 30 years or older. We can answer this question too using percentile ranks. First we need to find the percentage of values equal to or less than 29 years (the percentile rank of 29). The rest of the values must be 30 years or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage of players played half the number of games or less in the 2016-2017 season \n",
    "# (there are 34 games in the WNBAâ€™s regular season)\n",
    "percentile_rank_half_less = percentileofscore(a = wnba[\"Games Played\"], score = 17, kind = \"weak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "# Alternative Method\n",
    "print(wnba[\"Games Played\"].size)\n",
    "percentile_rank_half_less = wnba[\"Games Played\"].value_counts(normalize = True).sort_index().loc[:17].sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.91608391608392"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What percentage of players played more than half the number of games of the season 2016-2017\n",
    "\n",
    "percentage_half_more = 100 - percentile_rank_half_less\n",
    "percentage_half_more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find percentiles, we can use the Series.describe() method, which returns by default the 25th, the 50th, and the 75th percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    143.000000\n",
      "mean      27.076923\n",
      "std        3.679170\n",
      "min       21.000000\n",
      "25%       24.000000\n",
      "50%       27.000000\n",
      "75%       30.000000\n",
      "max       36.000000\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "min    21.0\n",
      "25%    24.0\n",
      "50%    27.0\n",
      "75%    30.0\n",
      "max    36.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(wnba[\"Age\"].describe())\n",
    "print()\n",
    "print((wnba[\"Age\"].describe()).iloc[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 25th, 50th, and 75th percentiles pandas returns by default are the scores that divide the distribution into four equal parts.\n",
    "\n",
    "The three percentiles that divide the distribution in four equal parts are also known as quartiles (from the Latin quartus which means four). There are three quartiles in the distribution of the Age variable:\n",
    "\n",
    "* The first quartile (also called lower quartile) is 24 (note that 24 is also the 25th percentile).\n",
    "* The second quartile (also called the middle quartile) is 27 (note that 27 is also the 50th percentile).\n",
    "* And the third quartile (also called the upper quartile) is 30 (note that 30 is also the 75th percentile)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may be interested to find the percentiles for percentages other than 25%, 50%, or 75%. For that, we can use the percentiles parameter of Series.describe(). This parameter requires us to pass the percentages we want as proportions between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min      21.0\n",
      "10%      23.0\n",
      "15%      23.0\n",
      "33%      25.0\n",
      "50%      27.0\n",
      "59.2%    28.0\n",
      "85%      31.0\n",
      "90%      32.0\n",
      "max      36.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(wnba['Age'].describe(percentiles = [.1, .15, .33, .5, .592, .85, .9]).iloc[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles don't have [a single standard definition](https://en.wikipedia.org/wiki/Percentile#Definitions), so don't be surprised if we get very similar (but not identical) values if you use different functions (especially if the functions come from different libraries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    143.000000\n",
      "mean      27.076923\n",
      "std        3.679170\n",
      "min       21.000000\n",
      "50%       27.000000\n",
      "75%       30.000000\n",
      "95%       34.000000\n",
      "max       36.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percentiles = wnba[\"Age\"].describe(percentiles = [.75,.95])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "27.0\n",
      "34.0\n"
     ]
    }
   ],
   "source": [
    "age_upper_quartile = percentiles.iloc[5]\n",
    "age_middle_quartile = percentiles.iloc[4]\n",
    "age_95th_percentile = percentiles.iloc[6]\n",
    "print(age_upper_quartile)\n",
    "print(age_middle_quartile)\n",
    "print(age_95th_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With frequency tables, we're trying to transform relatively large and incomprehensible amounts of data to a table format we can understand. However, not all frequency tables are straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0      1\n",
      "57.0      1\n",
      "58.0      1\n",
      "59.0      2\n",
      "62.0      1\n",
      "63.0      3\n",
      "64.0      5\n",
      "65.0      4\n",
      "66.0      8\n",
      "67.0      1\n",
      "68.0      2\n",
      "69.0      2\n",
      "70.0      3\n",
      "71.0      2\n",
      "73.0      6\n",
      "74.0      4\n",
      "75.0      4\n",
      "76.0      4\n",
      "77.0     10\n",
      "78.0      5\n",
      "79.0      6\n",
      "80.0      3\n",
      "81.0      5\n",
      "82.0      4\n",
      "83.0      4\n",
      "84.0      9\n",
      "85.0      2\n",
      "86.0      7\n",
      "87.0      6\n",
      "88.0      6\n",
      "89.0      3\n",
      "90.0      2\n",
      "91.0      3\n",
      "93.0      3\n",
      "95.0      2\n",
      "96.0      2\n",
      "97.0      1\n",
      "104.0     2\n",
      "108.0     1\n",
      "113.0     2\n",
      "Name: Weight, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wnba['Weight'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of granularity in the table above, but for this reason it's not easy to find patterns. The table for the Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the variable is measured on an interval or ratio scale, a common solution to this problem is to group the values in equal intervals. For the Weight variable, the values range from 55 to 113 kg, which amounts to a difference of 58 kg. We can try to segment this 58 kg interval in ten smaller and equal intervals. This will result in ten intervals of 5.8 kg each:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, pandas can handle this process gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54.941, 60.8]     5\n",
      "(60.8, 66.6]      21\n",
      "(66.6, 72.4]      10\n",
      "(72.4, 78.2]      33\n",
      "(78.2, 84.0]      31\n",
      "(84.0, 89.8]      24\n",
      "(89.8, 95.6]      10\n",
      "(95.6, 101.4]      3\n",
      "(101.4, 107.2]     2\n",
      "(107.2, 113.0]     3\n",
      "Name: Weight, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wnba['Weight'].value_counts(bins = 10).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ( character indicates that the starting point is not included, while the ] indicates that the endpoint is included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(54.941, 60.8], (60.8, 66.6] or (107.2, 113.0] are number intervals. The interval (54.941, 60.8] contains all real numbers greater than 54.941 and less than or equal to 60.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are 10 equal intervals, 5.8 each. The first interval, (54.941, 60.8] is confusing, and has to do with how pandas internals show the output. One way to understand this is to convert 54.941 to 1 decimal point, like all the other values are. Then the first interval becomes (54.9, 60.8]. 54.9 is not included, so you can think that the interval starts at the minimum value of the Weight variable, which is 55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we group values in a table to get a better sense of frequencies in the distribution, the table we generated above is also known as a **grouped frequency distribution table**. Each group (interval) in a grouped frequency distribution table is also known as a **class interval**. (107.2, 113.0], for instance, is a class interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525.8, 584.0]     3.496503\n",
       "(467.6, 525.8]     2.797203\n",
       "(409.4, 467.6]     5.594406\n",
       "(351.2, 409.4]     6.993007\n",
       "(293.0, 351.2]     5.594406\n",
       "(234.8, 293.0]    11.888112\n",
       "(176.6, 234.8]    13.986014\n",
       "(118.4, 176.6]    11.888112\n",
       "(60.2, 118.4]     16.783217\n",
       "(1.417, 60.2]     20.979021\n",
       "Name: PTS, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a grouped frequency distribution table for the PTS variable with the following characteristics:\n",
    "\n",
    "# The table has 10 class intervals.\n",
    "# For each class interval, the table shows percentages instead of frequencies.\n",
    "# The class intervals are sorted in descending order\n",
    "\n",
    "grouped_freq_table = wnba[\"PTS\"].value_counts(bins = 10, normalize = True).sort_index(ascending = False)*100\n",
    "grouped_freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we increase the number of class intervals, we can get more information, but the table becomes harder to analyze. When we decrease the number of class intervals, we get a boost in comprehensibility, but the amount of information in the table decreases.\n",
    "\n",
    "As a rule of thumb, 10 is a good number of class intervals to choose because it offers a good balance between information and comprehensibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.417, 118.4]    54\n",
      "(118.4, 234.8]    37\n",
      "(234.8, 351.2]    25\n",
      "(351.2, 467.6]    18\n",
      "(467.6, 584.0]     9\n",
      "Name: PTS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wnba['PTS'].value_counts(bins = 5).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we'd have to publish the table above in a blog post or a scientific paper. The readers will have a hard time understanding the intervals we chose. They'll also be puzzled by the decimal numbers because points in basketball can only be integers.\n",
    "\n",
    "To fix this, we can define the intervals ourselves. For the table above, we can define six intervals of 100 points each, and then count how many values fit in each interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntervalIndex([(0, 100], (100, 200], (200, 300], (300, 400], (400, 500], (500, 600]]\n",
       "              closed='right',\n",
       "              dtype='interval[int64]')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals = pd.interval_range(start = 0, end = 600, freq = 100)\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100]      0.0\n",
       "(100, 200]    0.0\n",
       "(200, 300]    0.0\n",
       "(300, 400]    0.0\n",
       "(400, 500]    0.0\n",
       "(500, 600]    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "gr_freq_table_6 = pd.Series(np.zeros(6), index = intervals)\n",
    "gr_freq_table_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100]      49.0\n",
       "(100, 200]    28.0\n",
       "(200, 300]    32.0\n",
       "(300, 400]    17.0\n",
       "(400, 500]    10.0\n",
       "(500, 600]     7.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in wnba[\"PTS\"]:\n",
    "#     if 0 < i <= 100:\n",
    "#         gr_freq_table_6.iloc[0] += 1\n",
    "#     elif 100 < i <= 200:\n",
    "#         gr_freq_table_6.iloc[1] += 1\n",
    "#     elif 200 < i <= 300:\n",
    "#         gr_freq_table_6.iloc[2] += 1\n",
    "#     elif 300 < i <= 400:\n",
    "#         gr_freq_table_6.iloc[3] += 1\n",
    "#     elif 400 < i <= 500:\n",
    "#         gr_freq_table_6.iloc[4] += 1\n",
    "#     elif 500 < i <= 600:\n",
    "#         gr_freq_table_6.iloc[5] += 1\n",
    "\n",
    "for i in wnba[\"PTS\"]:\n",
    "    for interval in intervals:\n",
    "        if i in interval:\n",
    "            gr_freq_table_6.loc[interval] += 1\n",
    "            break\n",
    "        \n",
    "gr_freq_table_6    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
